{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configuração básica do logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Define o nível mínimo de logs a serem capturados\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # Formato das mensagens de log\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"log_analysis.log\"),  # Escreve logs em um arquivo\n",
    "        logging.StreamHandler(sys.stdout)  # Exibe logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Criação de um logger para este módulo\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./.env')\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Rag Simples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Criacao de Log (P1)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    event_log_base = pd.read_csv(\"datasets/teste.csv\")\n",
    "    logger.info(f\"Dataset carregado com sucesso. Número de registros: {len(event_log_base)}.\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Arquivo de CSV nao encontrado: {e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar dataset: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def create_document(row):\n",
    "    try:\n",
    "        content = f\"\"\"\n",
    "        Machine name: {row['MachineName']}.\n",
    "        Category: {row['Category']}.\n",
    "        Entry type: {row['EntryType']}.\n",
    "        Message: {row['Message'].lower()}.\n",
    "        Source: {row['Source']}.\n",
    "        Time generated: {row['TimeGenerated']}.\n",
    "        country: {row['country']},\n",
    "        regionName: {row['regionName']},\n",
    "        city: {row['city']}\n",
    "        \"\"\"\n",
    "        # Melhora na estrutura da variavel doc (P1)\n",
    "        doc = Document(\n",
    "            page_content=content, \n",
    "            metadata={\n",
    "                \"Machine name\": row['MachineName'],\n",
    "                \"Category\": row['Category'],\n",
    "                \"Entry type\": row['EntryType'],\n",
    "                \"Message\": row['Message'].lower(),\n",
    "                \"Source\": row['Source'],\n",
    "                \"Time generated\": row['TimeGenerated'],\n",
    "                \"country\": row['country'],\n",
    "                \"regionName\": row['regionName'],\n",
    "                \"city\": row['city'],\n",
    "            }\n",
    "        )\n",
    "        logger.debug(f\"Documento criado para MachineName: {row['MachineName']}, Entry Type: {row['EntryType']}.\")\n",
    "        return doc\n",
    "    except KeyError as e:\n",
    "        logger.warning(f\"Chave ausente no row: {e}. Row: {row}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao criar documento: {e}. Row: {row}\")\n",
    "        return None\n",
    "\n",
    "logger.info(\"Criando documentos a partir do dataset.\")\n",
    "docs = [create_document(row) for _, row in event_log_base.iterrows()]\n",
    "\n",
    "# Remover documentos que não foram criados devido a erros (P1)\n",
    "# Adicao de loggers necessarios para boa compreensao do pipeline (P1)\n",
    "\n",
    "docs = [doc for doc in docs if doc is not None]\n",
    "logger.info(f\"Total de documentos criados: {len(docs)}.\")\n",
    "\n",
    "logger.debug(f\"Tamanho do conteúdo do primeiro documento: {len(docs[0].page_content)} caracteres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Adicao do logging para a geracao do Llamma (P1)\n",
    "\n",
    "try:\n",
    "    logger.info(\"Configurando o modelo OllamaLLM.\")\n",
    "    llm = OllamaLLM(model=\"llama3.2\", temperature=0) # Alteracao do 1lama 3.1 para o 3.2 (P1)\n",
    "    logger.info(\"Modelo OllamaLLM configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar o modelo OllamaLLM: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import SpacyTextSplitter\n",
    "\n",
    "# Adicao de Logging para o spliting (P1)\n",
    "try:\n",
    "    logger.info(\"Configurando o SpacyTextSplitter.\")\n",
    "    text_splitter = SpacyTextSplitter(chunk_size=1024, chunk_overlap=256, pipeline='pt_core_news_sm')\n",
    "    logger.info(\"SpacyTextSplitter configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar o SpacyTextSplitter: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Adicao do retorno do total e logging (P1)\n",
    "\n",
    "logger.info(\"Dividindo os documentos em chunks.\")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "logger.info(f\"Total de chunks criados: {len(all_splits)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Potencial melhoria: buscar ou treinar um modelo de embeddings pré-treinado para trabalhar com logs\n",
    "\n",
    "# Adicao do output de logging para a configuracao do huggingface (P1)\n",
    "try:\n",
    "    logger.info(\"Configurando o HuggingFaceEmbeddings.\")\n",
    "    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    # Possivel melhoria: Rodar em uma GPU da Nvidia usando o pytorch e kuda (P1)\n",
    "    model_kwargs = {'device': 'cpu'}    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "    logger.info(\"HuggingFaceEmbeddings configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar HuggingFaceEmbeddings: {e}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Adicao do output de logging para configuracao do Chroma (P1)\n",
    "try:\n",
    "    logger.info(f\"Criando o Chroma vectorstore a partir dos chunks.\") \n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_splits, \n",
    "        # Correcao Minoritaria de Codigo (P1)\n",
    "        embedding=embeddings\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar o Chroma Vectorstore: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    try:\n",
    "        formatted = \"\\n\\n\".join(\n",
    "            f\"Metadados: {doc.metadata}\\nConteúdo:\\n{doc.page_content}\" for doc in docs\n",
    "        )\n",
    "        # logger.debug(\"Documentos formatados para o prompt.\")\n",
    "        return formatted\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao formatar documentos: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "template = \"\"\"\n",
    "Utilize as informações abaixo como contexto para responder à pergunta de forma clara, precisa e completa.  \n",
    "Sempre que possível, cite trechos relevantes das fontes fornecidas para embasar sua resposta.  \n",
    "Se a resposta não puder ser determinada a partir do contexto, diga apenas que não sabe. Não tente inventar.\n",
    "\n",
    "### Contexto Disponível:\n",
    "{context}\n",
    "\n",
    "### Pergunta:\n",
    "{question}\n",
    "\n",
    "### Resposta Útil:\"\"\"\n",
    "\n",
    "try:\n",
    "    # logger.info(\"Criando o PromptTemplate para o RAG Chain.\")\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    # logger.info(\"PromptTemplate criado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao criar PromptTemplate: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    # logger.info(\"Configurando o RAG Chain com EnsembleRetriever.\")\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | custom_rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    # logger.info(\"RAG Chain configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar RAG Chain: {e}\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual foi a mensagem registrada pelo sistema no evento gerado em '2020-11-01 06:38:50' pelo 'SecurityCenter'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual foi a mensagem e o horário de término da transação do Windows Installer para o arquivo 'c2rintloc.en-us.16.msi' com id de processo '14504' em 2020-11-13?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual é o ID do processo cliente registrado para o término da transação do Windows Installer referente ao arquivo 'c2rint64.16.msi' em '2020-10-26'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual foi o erro identificado no evento com timestamp '2020-11-07 18:21:01', e qual o caminho do arquivo mencionado no registro correspondente?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual é a sequência de eventos relacionados ao serviço de Software Protection Platform entre '2020-11-10 16:30:50' e '2020-11-13 18:07:08', incluindo os motivos de re-agendamento e os resultados das verificações de status de licenciamento?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual problema foi identificado no evento do 'igfxCUIService2.0.0.0' registrado no timestamp '2020-11-01 06:38:49' com o Event ID '0'?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argos-ia-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
