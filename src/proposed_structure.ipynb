{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configuração básica do logging \n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Define o nível mínimo de logs a serem capturados\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # Formato das mensagens de log\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"log_analysis.log\"),  # Escreve logs em um arquivo\n",
    "        logging.StreamHandler(sys.stdout)  # Exibe logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Criação de um logger para este módulo\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv('./.env')\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Demo LangSmith\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Criação de Log (P1)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Carrega o dataset de logs de eventos\n",
    "try:\n",
    "    event_log_base = pd.read_csv(\"datasets/teste.csv\")\n",
    "    logger.info(f\"Dataset carregado com sucesso. Número de registros: {len(event_log_base)}.\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Arquivo de CSV nao encontrado: {e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar dataset: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def create_document(row):\n",
    "    \"\"\" Cria um documento a partir de uma linha do DataFrame.\n",
    "    Args: \n",
    "        row (pd.Series): Linha do DataFrame contendo os dados do log de eventos.\n",
    "    Returns:\n",
    "        Document: Um objeto Document contendo o conteúdo e metadados do log.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = f\"\"\"\n",
    "        Machine name: {row['MachineName']}.\n",
    "        Category: {row['Category']}.\n",
    "        Entry type: {row['EntryType']}.\n",
    "        Message: {row['Message'].lower()}.\n",
    "        Source: {row['Source']}.\n",
    "        Time generated: {row['TimeGenerated']}.\n",
    "        \"\"\"\n",
    "        doc = Document(\n",
    "            page_content=content, \n",
    "            metadata={\n",
    "                \"Machine name\": row['MachineName'], \n",
    "                \"Entry type\": row['EntryType'], \n",
    "                \"Time generated\": row['TimeGenerated'],\n",
    "                \"Source\": row['Source']\n",
    "            }\n",
    "        )\n",
    "        logger.debug(f\"Documento criado para MachineName: {row['MachineName']}, Entry Type: {row['EntryType']}.\")\n",
    "        return doc\n",
    "    except KeyError as e:\n",
    "        logger.warning(f\"Chave ausente no row: {e}. Row: {row}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao criar documento: {e}. Row: {row}\")\n",
    "        return None\n",
    "\n",
    "logger.info(\"Criando documentos a partir do dataset.\")\n",
    "docs = [create_document(row) for _, row in event_log_base.iterrows()]\n",
    "\n",
    "# Remover documentos que não foram criados devido a erros\n",
    "docs = [doc for doc in docs if doc is not None]\n",
    "logger.info(f\"Total de documentos criados: {len(docs)}.\")\n",
    "\n",
    "logger.debug(f\"Tamanho do conteúdo do primeiro documento: {len(docs[0].page_content)} caracteres.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Configuração do modelo OllamaLLM\n",
    "try:\n",
    "    logger.info(\"Configurando o modelo OllamaLLM.\")\n",
    "    llm = OllamaLLM(model=\"llama3.2\", temperature=0) # Ajuste a temperatura conforme necessário\n",
    "    logger.info(\"Modelo OllamaLLM configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar o modelo OllamaLLM: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting and storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import SpacyTextSplitter\n",
    "\n",
    "# Configuração do SpacyTextSplitter\n",
    "try:\n",
    "    logger.info(\"Configurando o SpacyTextSplitter.\")\n",
    "    text_splitter = SpacyTextSplitter(chunk_size=1024, chunk_overlap=256, pipeline='pt_core_news_sm')\n",
    "    logger.info(\"SpacyTextSplitter configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar o SpacyTextSplitter: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Dividindo os documentos em chunks\n",
    "logger.info(\"Dividindo os documentos em chunks.\")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "logger.info(f\"Total de chunks criados: {len(all_splits)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Configuração do HuggingFaceEmbeddings e definição do dispositivo \n",
    "try:\n",
    "    logger.info(\"Configurando o HuggingFaceEmbeddings.\")\n",
    "    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    model_kwargs = {'device': 'cpu'}    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "    logger.info(\"HuggingFaceEmbeddings configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar HuggingFaceEmbeddings: {e}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Configuração do Chroma Vectorstore\n",
    "try:\n",
    "    logger.info(f\"Criando o Chroma vectorstore a partir dos chunks.\") \n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_splits,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar o Chroma Vectorstore: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever, TFIDFRetriever\n",
    "\n",
    "# Configuração do BM25Retriever e TFIDFRetriever\n",
    "try:\n",
    "    logger.info(\"Configurando o BM25Retriever.\")\n",
    "    bm25_retriever = BM25Retriever.from_documents(all_splits)\n",
    "    tfidf_retriever = TFIDFRetriever.from_documents(all_splits)\n",
    "    bm25_retriever.k = 7\n",
    "    tfidf_retriever.k = 7\n",
    "    logger.info(\"BM25Retriever e TFIDFRetriever configurado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar BM25Retriever: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # relevância marginal máxima (MMR) \n",
    "# # seleciona exemplos com base em uma combinação de quais exemplos são mais semelhantes às entradas, ao mesmo tempo em que otimiza a diversidade.\n",
    "# retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 20})\n",
    "# # retrieved_docs = retriever.invoke(\"Quais são os eventos mais recentes relacionados ao Firewall?\")\n",
    "# retrieved_docs = retriever.invoke(\"Quais logs indicam algum erro?\")\n",
    "\n",
    "# len(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# # Adicao de logging para a configuracao do MMR usando MultiQueryRetriever\n",
    "# try:\n",
    "#     logger.info(\"Configurando o MultiQueryRetriever com MMR.\")\n",
    "#     retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "#         retriever=vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 20}), \n",
    "#         llm=llm\n",
    "#     )\n",
    "#     logger.info(\"MultiQueryRetriever configurado com sucesso.\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Erro ao configurar MultiQueryRetriever: {e}\")\n",
    "#     sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# Configuração do EnsembleRetriever combinando BM25 e TFIDF\n",
    "try:\n",
    "    logger.info(\"Configurando o EnsembleRetriever combinando BM25 e Similarity Retriever.\")\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, tfidf_retriever], \n",
    "        weights=[0.5, 0.5]  # Ajuste o peso conforme necessário\n",
    "    )\n",
    "    logger.info(\"EnsembleRetriever configurado com sucesso.\")\n",
    "    retrieved_docs = ensemble_retriever.invoke(\"Qual foi a mensagem registrada pelo sistema no evento gerado em '2020-11-01 06:38:50' pelo 'SecurityCenter'?\")\n",
    "    len(retrieved_docs)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar EnsembleRetriever: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir o número de documentos recuperados e filtrar por data\n",
    "print(len(retrieved_docs))\n",
    "target_date = \"2020-11-01 06:38:50\"\n",
    "\n",
    "for i in retrieved_docs:\n",
    "    if target_date in i.metadata['Time generated']:\n",
    "        print(i.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Definição do PromptTemplate para extração de informações relevantes\n",
    "custom_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=(\n",
    "        \"Você é um assistente especialista em análise de logs de eventos de segurança. \"\n",
    "        \"Dado o seguinte evento registrado no sistema, extraia as informações mais relevantes que respondam à pergunta.\\n\\n\"\n",
    "        \"Pergunta: {question}\\n\\n\"\n",
    "        \"Registro de Evento:\\n{context}\\n\\n\"\n",
    "        \"Extração relevante:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Configuração do modelo de compressão LLM\n",
    "compressor_llm = OllamaLLM(model=\"gemma2:2b\", temperature=0.0, cache=False)\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(compressor_llm, prompt=custom_prompt_template)\n",
    "\n",
    "contextual_compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\" Formata os documentos para o prompt.\n",
    "    Args:\n",
    "        docs (list of Document): Lista de documentos a serem formatados.\n",
    "    Returns:\n",
    "        str: String formatada contendo metadados e conteúdo dos documentos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        formatted = \"\\n\\n\".join(\n",
    "            f\"Metadados: {doc.metadata}\\nConteúdo:\\n{doc.page_content}\" for doc in docs\n",
    "        )\n",
    "        # logger.debug(\"Documentos formatados para o prompt.\")\n",
    "        return formatted\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao formatar documentos: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "template = \"\"\"Você é um assistente especialista em análise de logs de eventos de segurança. \n",
    "Utilize as informações abaixo como contexto para responder à pergunta de forma clara, precisa e completa.  \n",
    "Sempre que possível, cite trechos relevantes das fontes fornecidas para embasar sua resposta.  \n",
    "Se a resposta não puder ser determinada a partir do contexto, diga apenas que não sabe. Não tente inventar.\n",
    "\n",
    "### Contexto Disponível:\n",
    "{context}\n",
    "\n",
    "### Pergunta:\n",
    "{question}\n",
    "\n",
    "### Resposta Útil:\"\"\"\n",
    "\n",
    "# Criação do PromptTemplate para o RAG Chain\n",
    "try:\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao criar PromptTemplate: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Configuração do RAG Chain\n",
    "try:\n",
    "    rag_chain = (\n",
    "        {\"context\": contextual_compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | custom_rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar RAG Chain: {e}\")\n",
    "    sys.exit(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual foi a mensagem registrada pelo sistema no evento gerado em '2020-11-01 06:38:50' pelo 'SecurityCenter'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual foi a mensagem e o horário de término da transação do Windows Installer para o arquivo 'c2rintloc.en-us.16.msi' com id de processo '14504' em 2020-11-13?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual é o ID do processo cliente registrado para o término da transação do Windows Installer referente ao arquivo 'c2rint64.16.msi' em '2020-10-26'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual foi o erro identificado no evento com timestamp '2020-11-07 18:21:01', e qual o caminho do arquivo mencionado no registro correspondente?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual é a sequência de eventos relacionados ao serviço de Software Protection Platform entre '2020-11-10 16:30:50' e '2020-11-13 18:07:08', incluindo os motivos de re-agendamento e os resultados das verificações de status de licenciamento?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qual problema foi identificado no evento do 'igfxCUIService2.0.0.0' registrado no timestamp '2020-11-01 06:38:49' com o Event ID '0'?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argos-ia-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
